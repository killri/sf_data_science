{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества кластеризации: внутренние меры"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутренние меры - это способ оценки качества кластеризации, без правильных ответов, ориентируясь только на данные, которые мы кластеризировали\n",
    "\n",
    "В библиотеке sklearn реализованы три наиболее популярные метрики:\n",
    "\n",
    "* коэффициент силуэта (Silhouette Coefficient);\n",
    "* индекс Калински — Харабаса (Calinski-Harabasz Index);\n",
    "* индекс Дэвиса — Болдина (Davies-Bouldin Index)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### КОЭФФИЦИЕНТ СИЛУЭТА"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это тот же самый коэфицент, который использовался для определения оптимального числа кластеров алгоритмах, где коэфицент надо было задавать."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэфицент силуэта = $\\overline{s} = \\frac{1}{N} \\sum_{i=1}^N \\frac{b_i-a_i}{max(a_i,b_i)}$, где $a_i$ - это среднее расстояние от $x_i$ до объектов своего кластера, а $b_i$ - это среднее расстояние от $x_i$ до объектов ближайшего другого кластера"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение коэффициента силуэта всегда находится в диапазоне [−1,1].\n",
    "\n",
    "* Значение близко к −1: объекты в кластерах разрознены, и в целом кластерную структуру не удалось выделить.\n",
    "* Значение близко к 0: кластеры пересекаются друг с другом.\n",
    "* Значение близко к 1: чёткая кластерная структура с «плотными», отделёнными друг от друга кластерами."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ИНДЕКС КАЛИНСКИ — ХАРАБАСА\n",
    "\n",
    "Показывает отношение между разбросом значений между кластерами и разбросом значений внутри кластеров и вычисляется по следующей формуле:\n",
    "\n",
    "$\\frac{SS_B}{SS_W}\\times\\frac{N-K}{K-1}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной формуле:\n",
    "\n",
    "* N — общее количество объектов;\n",
    "* K — количество кластеров;\n",
    "* $SS_B$ — взвешенная межкластерная сумма квадратов расстояний;\n",
    "* $SS_W$ — внутрикластерная сумма квадратов расстояний."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$SS_B=\\sum_{k=1}^{K} n_{k} \\times\\left\\|C_{k}-C\\right\\|^{2}$\n",
    "\n",
    "В данной формуле:\n",
    "\n",
    "* $n_k$ — количество наблюдений в кластере k;\n",
    "* $C_k$ — центроид кластера k;\n",
    "* $C$ — центроид всего набора данных;\n",
    "* $K$— количество кластеров."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутрикластерная сумма для кластера $k$ равна $SS_B^k = \\sum_{i=1}^{n_k}  \\times\\left\\|X_{ik}-C_k\\right\\|^{2}$\n",
    "\n",
    "В данной формуле:\n",
    "\n",
    "* $n_k$ — количество наблюдений в кластере k;\n",
    "* $C_k$ — центроид кластера k;\n",
    "* $X_{ik}$— i-ое наблюдение в кластере k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$SS_B = \\sum_{k=1}^K SS_B^k$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно отметить, что нет никакого «приемлемого» порогового значения индекса — скорее, его можно использовать для того, чтобы сравнивать разные разбиения на кластеры между собой: более высокое значение индекса будет означать, что кластеры плотные (т. е. объекты внутри них находятся близко друг к другу) и хорошо разделены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#В библиотеке sklearn данный алгоритм реализуется с помощью метода calinski_harabasz_score():\n",
    "\n",
    "#определяем алгоритм кластеризации\n",
    "#km = KMeans(n_clusters=3, random_state=42)\n",
    "#обучаем его на наших данных\n",
    "#km.fit_predict(X)\n",
    "#вычисляем значение коэффициента Калински — Харабаса\n",
    "#score = calinski_harabasz_score(X, km.labels_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ИНДЕКС ДЭВИСА — БОЛДИНА (DBI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаги вычисления:\n",
    "\n",
    "1. Bычисляем для каждого кластера следующую меру разброса значений внутри него: $S_{k}=(\\frac{1}{n_{k}} \\sum_{i=1}^{n_{k}}\\left|X_{i k}-C_{k}\\right|^{q})^{\\frac{1}{q}}$\n",
    "    * $n_k$ - мощность кластера $k$\n",
    "    * $q$ - обячно = 2, и тогда расстояние Евклидово\n",
    "    * Остальное все как в предыдущем индексе\n",
    "2. Далее находим расстояния между центроидами кластеров: $M_{i, j}=\\left\\|C_{i}-C_{j}\\right\\|_{q}$\n",
    "3. Теперь для каждой пары кластеров вычисляем следующее отношение: $R_{i j}=\\frac{S_{i}+S_{j}}{M_{i j}}$. Также для каждого кластера находим максимум из полученных значений: $R_i\\equiv maximum (R_{ij})$\n",
    "4. $DBI=\\frac{1}{N}\\sum^{N}_{i=1}R_i$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индекс показывает среднюю «схожесть» между кластерами, и 0 — это минимально возможное значение. Разумеется, так как мы хотим, чтобы кластеры были максимально различными (т. е. имели низкую схожесть), мы должны пытаться достичь как можно более маленького значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#В библиотеке sklearn индекс Дэвиса — Болдина реализуется с помощью метода davies_bouldin_score():\n",
    "\n",
    "#определяем алгоритм кластеризации\n",
    "#km = KMeans(n_clusters=3, random_state=42)\n",
    "#обучаем его на наших данных\n",
    "#km.fit_predict(X)\n",
    "#вычисляем значение коэффициента Дэвиса — Болдина\n",
    "#score = davies_bouldin_score(X, km.labels_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ВНУТРИКЛАСТЕРНОЕ РАССТОЯНИЕ\n",
    "\n",
    "Для того чтобы оценить качество кластеризации, можно вычислить суммарное внутрикластерное расстояние:\n",
    "\n",
    "$F_0 = \\sum_{k=1}^{K} \\sum_{i=1}^{N}\\left[a\\left(x_{i}\\right)=k\\right] \\rho\\left(x_{i}, c_{k}\\right)$\n",
    "\n",
    "Разумеется, сумма этих расстояний должна быть минимальной — это тот случай, когда все элементы кластера совпадают с центроидом."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### МЕЖКЛАСТЕРНОЕ РАССТОЯНИЕ\n",
    "\n",
    "Аналогично суммарному внутрикластерному расстоянию, вводится межкластерное расстояние:\n",
    "\n",
    "$F_0 = \\sum_{i, j=1}^{N}\\left[a\\left(x_{i}\\right) \\neq a\\left(x_{j}\\right)\\right] \\rho\\left(x_{i}, x_{j}\\right)$\n",
    "\n",
    "Мы проверяем, что предсказания о принадлежности к кластеру не равны (т. е. объекты относятся к разным кластерам), и считаем расстояние между этими объектами (можем использовать различные функции расстояний). Здесь мы, разумеется, будем максимизировать результат, так как нам важно, чтобы элементы из разных кластеров были как можно меньше похожи друг на друга, а значит, чтобы расстояние между ними было как можно больше."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ОТНОШЕНИЕ РАССТОЯНИЙ\n",
    "\n",
    "Логичным образом из предыдущих двух метрик (внутрикластерного и межкластерного расстояний) мы получаем отношение расстояний:\n",
    "\n",
    "$\\frac{F_0}{F_1}\\rightarrow \\min$\n",
    "\n",
    "Таким образом мы можем учитывать оба функционала, рассмотренные ранее (расстояние внутри кластера и между кластерами), и оптимизировать отношение расстояний. Естественно, нам нужно, чтобы оно было минимальным — это будет достигаться, если расстояние между кластерами максимально, а внутри кластера — минимально."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества кластеризации: внешние меры"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
