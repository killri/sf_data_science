{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10299, 561)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/train.txt\", \"r\") as file:\n",
    "    contents = file.readlines()\n",
    "    \n",
    "for i, x in enumerate(contents):\n",
    "    contents[i] = x.split()\n",
    "    \n",
    "for i in range(len(contents)):\n",
    "    for j in range(len(contents[0])):\n",
    "        contents[i][j] = np.float64(contents[i][j])\n",
    "        \n",
    "X_train = contents  \n",
    "\n",
    "with open(\"data/test.txt\", \"r\") as file:\n",
    "    contents = file.readlines()\n",
    "    \n",
    "for i, x in enumerate(contents):\n",
    "    contents[i] = x.split()\n",
    "    \n",
    "for i in range(len(contents)):\n",
    "    for j in range(len(contents[0])):\n",
    "        contents[i][j] = np.float64(contents[i][j])\n",
    "        \n",
    "X_test = contents\n",
    "\n",
    "X = X_train\n",
    "for x in X_test:\n",
    "    X.append(x)\n",
    "    \n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10299"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/train_labels.txt\", \"r\") as file:\n",
    "    contents = file.readlines()\n",
    "    \n",
    "for i, x in enumerate(contents):\n",
    "    contents[i] = x.split()\n",
    "    \n",
    "for i in range(len(contents)):\n",
    "    for j in range(len(contents[0])):\n",
    "        contents[i][j] = np.float64(contents[i][j])\n",
    "        \n",
    "y_train = contents  \n",
    "\n",
    "with open(\"data/test_labels.txt\", \"r\") as file:\n",
    "    contents = file.readlines()\n",
    "    \n",
    "for i, x in enumerate(contents):\n",
    "    contents[i] = x.split()\n",
    "    \n",
    "for i in range(len(contents)):\n",
    "    for j in range(len(contents[0])):\n",
    "        contents[i][j] = np.float64(contents[i][j])\n",
    "        \n",
    "y_test = contents\n",
    "\n",
    "y = y_train\n",
    "for x in y_test:\n",
    "    y.append(x)\n",
    "    \n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0    1944\n",
       "5.0    1906\n",
       "4.0    1777\n",
       "1.0    1722\n",
       "2.0    1544\n",
       "3.0    1406\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4.3\n",
    "\n",
    "Далее необходимо отмасштабировать признаки. Будем использовать для этого алгоритм StandardScaler. Примените его ко всем значениям признаков и впишите в качестве ответа значение первого признака для первого объекта, предварительно округлив его до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "round(X_scaled[0][0],2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4.4\n",
    "\n",
    "Пора переходить к кластеризации. Для начала определите оптимальное количество кластеров, используя внутренние меры кластеризации. Используйте все известные вам коэффициенты, реализуемые в библиотеке sklearn: коэффициент силуэта, индекс Калински — Харабаса и индекс Дэвиса — Болдина. В качестве алгоритма возьмите k-means++, в качестве значения параметра random_state — число 42.\n",
    "\n",
    "Выведите оптимальное количество кластеров для каждой метрики, перебирая значения от 2 до 9 включительно. Также введите значение каждой метрики, округлённое до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\killr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\killr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\killr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\killr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\killr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\killr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\killr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\killr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2, 0.3937324764077081, 7880.813903657111, 1.070744182238566],\n",
       " [3, 0.31548375272734164, 5034.4752572242, 1.786516465365282],\n",
       " [4, 0.15052911849826184, 3696.3381978005555, 2.3409301040454653],\n",
       " [5, 0.12723671885995455, 3027.0761722557045, 2.431375173184108],\n",
       " [6, 0.11096892121098482, 2556.7735736855657, 2.367036374724895],\n",
       " [7, 0.08541910378666204, 2216.563937360621, 2.681979507531904],\n",
       " [8, 0.07618332955957029, 1974.9714963243528, 2.6112259939773117],\n",
       " [9, 0.07648837092046105, 1790.9531728187399, 2.5818882774756022]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "res_list = list()\n",
    "for n_clust in range(2,10):\n",
    "    kmeans = KMeans(random_state=42, n_clusters=n_clust)\n",
    "    kmeans.fit(X_scaled)\n",
    "    sil = silhouette_score(X_scaled,kmeans.labels_)\n",
    "    dbs = davies_bouldin_score(X_scaled,kmeans.labels_)\n",
    "    chs = calinski_harabasz_score(X_scaled,kmeans.labels_)\n",
    "    res_list.append([n_clust, sil, chs, dbs])\n",
    "\n",
    "res_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4.5\n",
    "\n",
    "Теперь давайте оценим качество кластеризации с точки зрения внешних мер. Реализуйте кластеризацию с помощью классической версии алгоритма k-means. Пусть количество кластеров будет соответствовать количеству активностей. Параметр random_state = 42. В качестве ответов введите значения получившихся мер, предварительно округлив их до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\killr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homogeneity_score: 0.58\n",
      "completeness_score: 0.54\n",
      "adjusted_rand_score: 0.42\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=42, init='random')\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, adjusted_rand_score\n",
    "\n",
    "print('homogeneity_score:', round(homogeneity_score(kmeans.labels_, y),2))\n",
    "print('completeness_score:', round(completeness_score(kmeans.labels_, y),2))\n",
    "print('adjusted_rand_score:', round(adjusted_rand_score(kmeans.labels_, y),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeyClust  MyAlgClust\n",
       "1.0       3.0            903\n",
       "          5.0            741\n",
       "          4.0             78\n",
       "2.0       3.0           1242\n",
       "          5.0            295\n",
       "          4.0              5\n",
       "          6.0              2\n",
       "3.0       5.0            889\n",
       "          3.0            321\n",
       "          4.0            196\n",
       "4.0       2.0           1238\n",
       "          6.0            447\n",
       "          1.0             91\n",
       "          3.0              1\n",
       "5.0       2.0           1346\n",
       "          6.0            560\n",
       "6.0       1.0           1556\n",
       "          6.0            329\n",
       "          2.0             54\n",
       "          3.0              5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df = pd.DataFrame([list(kmeans.labels_), list(y)], index=['MyAlgClust', 'KeyClust'])\n",
    "check_df = check_df.T\n",
    "check_df['MyAlgClust'] = check_df['MyAlgClust']+1\n",
    "check_df.groupby('KeyClust').value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4.7\n",
    "\n",
    "Теперь попробуйте реализовать алгоритм k-means для двух кластеров (для того числа активностей, которое является оптимальным с точки зрения внутренних мер) и снова посмотреть, как алгоритм разобьёт активности по кластерам. Как и в предыдущем задании, нумерацию кластеров начинайте с 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\killr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KeyClust  MyAlgClust\n",
       "1.0       1.0           1722\n",
       "2.0       1.0           1536\n",
       "          2.0              8\n",
       "3.0       1.0           1406\n",
       "4.0       2.0           1774\n",
       "          1.0              3\n",
       "5.0       2.0           1906\n",
       "6.0       2.0           1932\n",
       "          1.0             12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=42, init='random')\n",
    "kmeans.fit(X_scaled)\n",
    "check_df = pd.DataFrame([list(kmeans.labels_), list(y)], index=['MyAlgClust', 'KeyClust'])\n",
    "check_df = check_df.T\n",
    "check_df['MyAlgClust'] = check_df['MyAlgClust']+1\n",
    "check_df.groupby('KeyClust').value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4.8\n",
    "\n",
    "Вычислите значение полноты для разбиения на два кластера алгоритмом k-means. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979530559699631"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_score(y, kmeans.labels_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4.10\n",
    "\n",
    "Давайте сравним полученный результат с агломеративной иерархической кластеризацией. Реализуйте её также для двух кластеров и вычислите значение полноты.\n",
    "\n",
    "1. Какой алгоритм показывает наилучшее качество, если судить по полноте?\n",
    "2. Какое значение полноты получилось для агломеративной кластеризации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999993"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "ac = AgglomerativeClustering(n_clusters=2)\n",
    "ac.fit(X_scaled)\n",
    "completeness_score(y, ac.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
